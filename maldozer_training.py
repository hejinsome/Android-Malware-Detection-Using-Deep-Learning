from __future__ import print_function

import numpy as np
import re
import glob

from keras.utils.data_utils import get_file
from keras.layers.embeddings import Embedding
from keras import layers
from keras.layers import recurrent
from keras.models import Model
from keras.preprocessing.sequence import pad_sequences
import os
from keras.models import model_from_json

EMBED_HIDDEN_SIZE = 64
NO_OF_CONV_FILTERS = 256
NO_OF_CONV_SIZE = 3
API_SEQUENCE_MAX_LEN = 600
NUMBER_OF_API_CALLS = 6
NUMBER_OF_TRAINING_EXAMPLES_PER_BATCH = 4

all_api_calls_file = open('mixed_dataset/all_api_calls.txt')

all_api_calls = []
for lines in all_api_calls_file.readlines():
	all_api_calls.append(lines[:-1])


#api_index = dict((c,i+1) for i,c in enumerate(all_api_calls))

API_SEQUENCE_MAX_LEN = min(len(all_api_calls),600)

processed_and_indexed_training_examples = []
outputs = []
indexed_file = open('training_file_index_varthresh','r')
count = 0
for row in indexed_file.readlines():
	#print(row)
	count = count + 1
	#print(count)
	components = row.split('-')
	name = components[0]
	indexes = components[1]
	indexes = indexes.split(',')[:-1]
	if name[-1] == 'e':
		outputs.append([0,1])
	else:
		outputs.append([1,0])
	#print(name)
	#print(indexes)
	xlist = []
	for i in indexes:
		xlist.append(int(i))
	print(len(xlist))
	processed_and_indexed_training_examples.append(xlist)
	#break

indexed_file.close()





#print(outputs)
#print(processed_and_indexed_training_examples)

processed_and_indexed_training_examples = np.array(processed_and_indexed_training_examples)
outputs = np.array(outputs)


testing_preprocessed_and_indexed = processed_and_indexed_training_examples[1300:]
testing_outputs = outputs[1300:]

#processed_and_indexed_training_examples = processed_and_indexed_training_examples[:1300]
#outputs = outputs[:1300]

API_sequence = layers.Input(shape=(API_SEQUENCE_MAX_LEN,), dtype='int32')
embeded_sequence = layers.Embedding(len(all_api_calls), EMBED_HIDDEN_SIZE)(API_sequence)
conv_layer = layers.Conv1D(NO_OF_CONV_FILTERS,NO_OF_CONV_SIZE)(embeded_sequence)
activ_layer = layers.Activation('relu')(conv_layer)
global_max_pool = layers.GlobalMaxPooling1D()(activ_layer)
fc_layer = layers.Dense(256)(global_max_pool)
fc_relu = layers.Activation('relu')(fc_layer)
dropout_layer = layers.Dropout(0.5)(fc_relu)
final_layer = layers.Dense(2)(dropout_layer)
final_softmax_layer = layers.Activation('softmax')(final_layer)
model = Model(API_sequence,final_softmax_layer)
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
model.fit(processed_and_indexed_training_examples,outputs,epochs = 100,validation_split=0.0)

model_json = model.to_json()
with open("model_l1.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model_varthresh.h5")
print("Saved model to disk")
#results = model.evaluate(x=testing_preprocessed_and_indexed,y=testing_outputs)

#print(results)


